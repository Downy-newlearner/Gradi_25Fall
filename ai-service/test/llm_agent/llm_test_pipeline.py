import os
import csv
import base64
import re
import ast
import unicodedata
import time
from io import BytesIO
from dotenv import load_dotenv
from groq import Groq
from tqdm import tqdm
from PIL import Image
import pandas as pd

# OpenAIì™€ Gemini ì§€ì›ì„ ìœ„í•œ ì¶”ê°€ import
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install openaië¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install google-generativeaië¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")

load_dotenv()

# ----------------------
# ì´ë¯¸ì§€ ì²˜ë¦¬
# ----------------------
def resize_image_to_bytes(image_path, max_size=(1024, 1024)):
    try:
        with Image.open(image_path) as img:
            img = img.convert("RGB")
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            buffer = BytesIO()
            img.save(buffer, format="JPEG")
            buffer.seek(0)
            return buffer.read()
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {image_path} ({e})")
        with open(image_path, "rb") as f:
            return f.read()

def encode_image(image_path):
    image_bytes = resize_image_to_bytes(image_path)
    return base64.b64encode(image_bytes).decode("utf-8")

# ----------------------
# ê³µí†µ í”„ë¡¬í”„íŠ¸
# ----------------------
PROMPT_TEXT = """
*ì§€ì‹œ*: ë‹¤ìŒ ì´ë¯¸ì§€ëŠ” í•œêµ­ì˜ ìˆ˜í•™ ë¬¸ì œì§‘ ì¤‘ í•œ ë¬¸ì œì— ëŒ€í•œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„ í›„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
*ë§¥ë½*: ë¬¸ì œì˜ ë‹µì€ í•™ìƒ ì†ê¸€ì”¨ë¡œ ì‘ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    - ë¬¸ì œ ìœ í˜•: ê°ê´€ì‹ ë˜ëŠ” ì£¼ê´€ì‹ì…ë‹ˆë‹¤.
    - í•œ ë¬¸ì œ ë‚´ì— ê¼¬ë¦¬ ë¬¸ì œê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë‹µì€ í•œ ê°œ ì¼ ìˆ˜ë„ ìˆê³ , ì—¬ëŸ¬ ê°œ ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    
ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ë¥¼ ì°¸ê³ í•˜ë©°, ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚œ ì†ê¸€ì”¨ ì¤‘ ë‹µìœ¼ë¡œ ë³´ì´ëŠ” ë¶€ë¶„ì„ ì°¾ì•„ì£¼ì„¸ìš”.
*ì¶”ì¶œí•  ì •ë³´*: ë¬¸ì œ ë²ˆí˜¸, í•™ìƒì´ ì‘ì„±í•œ(ê³ ë¥¸) ë‹µ
*ì¶œë ¥ í˜•ì‹*:
    - ë¬¸ì œ ë²ˆí˜¸: í•™ìƒì´ ì‘ì„±í•œ(ê³ ë¥¸) ë‹µ \n\n
    - ë¬¸ì œ ë²ˆí˜¸ì—ëŠ” í•œ ë¬¸ì œì— ëŒ€í•œ ë²ˆí˜¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.
        - í•œêµ­ì˜ ìˆ˜í•™ ë¬¸ì œì§‘ì˜ ë¬¸ì œ ë²ˆí˜¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë„¤ ìë¦¬ ìˆ«ìë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
        - ë¬¸ì œ ë²ˆí˜¸ê°€ í•œ ìë¦¬ ìˆ«ìì¸ ê²½ìš°
            - ex. 0001
            - ì´ë¥¼ ì¶”ì¶œí•  ë•Œ ì•ì˜ 0ì„ ì œê±°í•˜ê³  1ìœ¼ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.
        - ë¬¸ì œ ë²ˆí˜¸ê°€ ë‘ ìë¦¬ ìˆ«ìì¸ ê²½ìš°
            - ex. 0010
            - ì´ë¥¼ ì¶”ì¶œí•  ë•Œ ì•ì˜ 0ì„ ì œê±°í•˜ê³  10ìœ¼ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.
        - ë¬¸ì œ ë²ˆí˜¸ê°€ ì„¸ ìë¦¬ ìˆ«ìì¸ ê²½ìš°
            - ex. 0189
            - ì´ë¥¼ ì¶”ì¶œí•  ë•Œ ì•ì˜ 0ì„ ì œê±°í•˜ê³  189ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.
        - ë¬¸ì œ ë²ˆí˜¸ê°€ ë„¤ ìë¦¬ ìˆ«ìì¸ ê²½ìš°
            - ex. 1780
            - ì´ë¥¼ ì¶”ì¶œí•  ë•Œ ë„¤ ìë¦¬ ìˆ«ì ê·¸ëŒ€ë¡œ í‘œê¸°í•©ë‹ˆë‹¤.
    - ê¼¬ë¦¬ ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°ì—ëŠ” ê¼¬ë¦¬ ë¬¸ì œ ë²ˆí˜¸ëŠ” ë‹µ ë¶€ë¶„ì— ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
*ì¶œë ¥ ì˜ˆì‹œ*:
    1. í•œ ë¬¸ì œì— ë‹µì´ í•œ ê°œì¸ ê²½ìš°
        - 1: 15
            - ì„¤ëª…: 1ë²ˆ ë¬¸ì œ, ë‹µì´ 15ë¼ëŠ” ì˜ë¯¸
        - 2: 7^2
            - ì„¤ëª…: 2ë²ˆ ë¬¸ì œ, ë‹µì´ 7^2(7ì˜ ì œê³±)ì´ë¼ëŠ” ì˜ë¯¸
            
    2. í•œ ë¬¸ì œì— ë‹µì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°
        - 3: [1, 2, 3]
            - ì„¤ëª…: 3ë²ˆ ë¬¸ì œ, ë‹µì´ 1, 2, ê·¸ë¦¬ê³  3ì´ë¼ëŠ” ì˜ë¯¸
        - 4: [3, 24]
            - ì„¤ëª…: 4ë²ˆ ë¬¸ì œ, ë‹µì´ 3 ê·¸ë¦¬ê³  24ë¼ëŠ” ì˜ë¯¸
        - 10: [ã„±, ã„·]
            - ì„¤ëª…: 10ë²ˆ ë¬¸ì œ, ë‹µì´ ã„± ê·¸ë¦¬ê³  ã„·ì´ë¼ëŠ” ì˜ë¯¸
            
    3. í•œ ë¬¸ì œì— ê¼¬ë¦¬ ë¬¸ì œ(sub question)ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš°
        - 5: [1:7, 2:11, 3:[8,9,10,11]]
            - ì„¤ëª…: 5ë²ˆ ë¬¸ì œì— ê¼¬ë¦¬ ë¬¸ì œ 1ë²ˆì€ ë‹µì´ 7, ê¼¬ë¦¬ ë¬¸ì œ 2ë²ˆì€ ë‹µì´ 11, ê¼¬ë¦¬ ë¬¸ì œ 3ë²ˆì€ ë‹µì´ 8,9,10, ê·¸ë¦¬ê³  11ì´ë¼ëŠ” ì˜ë¯¸
        - 6: [1:15, 2:10, 3:22]
            - ì„¤ëª…: 6ë²ˆ ë¬¸ì œì— ê¼¬ë¦¬ ë¬¸ì œ 1ë²ˆì€ ë‹µì´ 15, ê¼¬ë¦¬ ë¬¸ì œ 2ë²ˆì€ ë‹µì´ 10, ê¼¬ë¦¬ ë¬¸ì œ 3ë²ˆì€ ë‹µì´ 22ì´ë¼ëŠ” ì˜ë¯¸
        - 7: [a:55, b:13]
            - ì„¤ëª…: 7ë²ˆ ë¬¸ì œì— ê¼¬ë¦¬ ë¬¸ì œ aëŠ” ë‹µì´ 55, ê¼¬ë¦¬ ë¬¸ì œ bëŠ” ë‹µì´ 13ì´ë¼ëŠ” ì˜ë¯¸

ìœ„ ì§€ì‹œ, ë§¥ë½, ì¶”ì¶œ ì •ë³´, ì¶œë ¥ í˜•ì‹, ì¶œë ¥ ì˜ˆì‹œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ ë¬¸ì¥ì€ ì“°ì§€ ë§ê³  ì¶œë ¥ í˜•ì‹ì— ë§ê²Œ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

# ----------------------
# ê° APIë³„ í˜¸ì¶œ í•¨ìˆ˜
# ----------------------
def decode_image_groq(model, api_key, image_path):
    """Groq APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë””ì½”ë”©"""
    base64_image = encode_image(image_path)
    client = Groq(api_key=api_key)
    chat_completion = client.chat.completions.create(
        messages=[{
            "role": "user",
            "content": [
                {"type": "text", "text": PROMPT_TEXT},
                {"type": "image_url",
                 "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
            ]
        }],
        model=model,
    )
    return chat_completion.choices[0].message.content

def decode_image_openai(model, api_key, image_path):
    """OpenAI APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë””ì½”ë”©"""
    if not OPENAI_AVAILABLE:
        raise ImportError("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    base64_image = encode_image(image_path)
    client = openai.OpenAI(api_key=api_key)
    
    response = client.chat.completions.create(
        model=model,
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": PROMPT_TEXT},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                    }
                ]
            }
        ],
        max_tokens=1000
    )
    return response.choices[0].message.content

def decode_image_gemini(model, api_key, image_path):
    """Gemini APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë””ì½”ë”©"""
    if not GEMINI_AVAILABLE:
        raise ImportError("Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    genai.configure(api_key=api_key)
    
    # ëª¨ë¸ëª…ì—ì„œ 'models/' ì œê±° (ìˆëŠ” ê²½ìš°)
    model_name = model.replace('models/', '') if model.startswith('models/') else model
    
    # ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë¡œë“œ
    image_bytes = resize_image_to_bytes(image_path)
    
    # Gemini ëª¨ë¸ ì´ˆê¸°í™”
    model_instance = genai.GenerativeModel(model_name)
    
    # ì´ë¯¸ì§€ ê°ì²´ ìƒì„±
    image_part = {
        "mime_type": "image/jpeg",
        "data": image_bytes
    }
    
    # ìš”ì²­ ìƒì„±
    response = model_instance.generate_content([PROMPT_TEXT, image_part])
    return response.text

# ----------------------
# í†µí•© ì´ë¯¸ì§€ ë””ì½”ë”© í•¨ìˆ˜
# ----------------------
def decode_image(model, api_key, image_path):
    """ëª¨ë¸ì— ë”°ë¼ ì ì ˆí•œ APIë¥¼ ì„ íƒí•˜ì—¬ ì´ë¯¸ì§€ ë””ì½”ë”©"""
    model_lower = model.lower()
    
    if 'llama' in model_lower or 'groq' in model_lower:
        return decode_image_groq(model, api_key, image_path)
    elif 'gpt' in model_lower or 'openai' in model_lower:
        return decode_image_openai(model, api_key, image_path)
    elif 'gemini' in model_lower:
        return decode_image_gemini(model, api_key, image_path)
    else:
        # ê¸°ë³¸ì ìœ¼ë¡œ Groq API ì‚¬ìš©
        print(f"âš ï¸ ëª¨ë¸ '{model}'ì˜ API íƒ€ì…ì„ ìë™ ê°ì§€í•  ìˆ˜ ì—†ìŒ. Groq APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return decode_image_groq(model, api_key, image_path)

def safe_decode_image(model, api_key, image_path, retries=3, wait_sec=5):
    """ì•ˆì „í•œ ì´ë¯¸ì§€ ë””ì½”ë”© (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    for attempt in range(retries):
        try:
            return decode_image(model, api_key, image_path)
        except Exception as e:
            err_str = str(e)
            
            # ê³µí†µ ì—ëŸ¬ ì²˜ë¦¬
            if any(error in err_str for error in ["InternalServerError", "500", "internal_error"]):
                print(f"âš ï¸ ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {image_path} ({attempt+1}/{retries}) ëŒ€ê¸° {wait_sec}s")
                time.sleep(wait_sec)
            elif any(error in err_str for error in ["RateLimitError", "429", "rate_limit", "quota"]):
                wait_time = wait_sec * (10 if "openai" in model.lower() else 5)
                print(f"âš ï¸ ì†ë„ ì œí•œ ì˜¤ë¥˜: {image_path} ({attempt+1}/{retries}) ëŒ€ê¸° {wait_time}s")
                time.sleep(wait_time)
            elif "ImportError" in err_str:
                print(f"âš ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜: {e}")
                break
            else:
                print(f"âš ï¸ ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ: {image_path} ({e})")
                if attempt < retries - 1:
                    time.sleep(wait_sec)
                else:
                    break
    return None

# ----------------------
# ì‘ë‹µ íŒŒì‹± (ê¸°ì¡´ê³¼ ë™ì¼)
# ----------------------
def response_split(response):
    # None, NaN ë“± ì²˜ë¦¬
    if response is None:
        return None, None

    # ë¬¸ìì—´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
    if not isinstance(response, str):
        response = str(response)

    response = response.strip()
    if not response:
        return None, None

    # ì—¬ëŸ¬ ì¤„ ì²˜ë¦¬
    lines = [line.strip() for line in response.splitlines() if line.strip()]
    parsed_answers = {}
    q_num_main = None

    for line in lines:
        # ì• ê³µë°± ì œê±° í›„ ë§¤ì¹­
        match = re.match(r"^-?(\d+)\s*:\s*(.+)$", line)
        if match:
            q_num = int(match.group(1))
            ans = match.group(2).strip()

            # í•œê¸€ì´ í¬í•¨ë˜ê³  ','ê°€ ìˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬
            if re.search(r"[ã„±-ã…ê°€-í£]", ans) and "," in ans:
                ans_list = [a.strip(" ()") for a in ans.split(",") if a.strip()]
                parsed_answers[q_num] = ans_list
            else:
                parsed_answers[q_num] = ans

    if len(parsed_answers) == 1:
        q_num_main, answer = list(parsed_answers.items())[0]
        return q_num_main, answer

    return None, parsed_answers if parsed_answers else None

# ----------------------
# Annotation íŒŒì‹± (ê¸°ì¡´ê³¼ ë™ì¼)
# ----------------------
def split_top_level_commas(s):
    parts = []
    current = ''
    level = 0
    for c in s:
        if c == '[':
            level += 1; current += c
        elif c == ']':
            level -= 1; current += c
        elif c == ',' and level == 0:
            parts.append(current.strip())
            current = ''
        else:
            current += c
    if current: parts.append(current.strip())
    return parts

def parse_problem_info(input_str):
    top_level_parts = split_top_level_commas(input_str)
    if len(top_level_parts) < 4:
        raise ValueError(f"í˜•ì‹ ì˜¤ë¥˜: {input_str}")

    file_part = top_level_parts[0]
    problem_number = int(top_level_parts[1])
    type_str = top_level_parts[2]
    answer_str = ','.join(top_level_parts[3:])

    file_match = re.match(r"(.+?) - (\d+)_section_(\d+)_conf[\d.]+\.jpg", file_part)
    if not file_match:
        raise ValueError(f"íŒŒì¼ëª… í˜•ì‹ ì˜¤ë¥˜: {file_part}")

    book = file_match.group(1)
    page = int(file_match.group(2))
    section_number = int(file_match.group(3))

    return {"file": file_part, "book": book, "page": page,
            "section_number": section_number, "problem_number": problem_number,
            "type": type_str, "answer": answer_str}

def load_annotation_dict(annotation_file):
    mapping = {}
    with open(annotation_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line: continue
            parts = [p.strip() for p in line.split(',', 3)]
            if len(parts) < 4 or not parts[1].isdigit(): continue
            info = parse_problem_info(line)
            mapping[os.path.basename(info["file"])] = info
    return mapping

def clean_string(s):
    s = unicodedata.normalize("NFC", s)
    s = re.sub(r"\s+", "", s)
    s = re.sub(r"[\u200b\u200c\u200d\uFEFF]", "", s)
    return s.lower()

# ----------------------
# ì±„ì 
# ----------------------

char_to_num = {
    "â‘ ": "1",
    "â‘¡": "2",
    "â‘¢": "3",
    "â‘£": "4",
    "â‘¤": "5",
}

symbol_map = {
    "Ã—": "*",
    "Â²": "^2",
    "â¶": "^6",
}

def parse_value(val):
    """ë‹¨ì¼ ê°’, ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬ í‘œì¤€í™”"""
    if val is None:
        return None
    if isinstance(val, float) and np.isnan(val):
        return None
    if isinstance(val, (pd.Series, np.ndarray, list, tuple)):
        return [parse_value(v) for v in val]

    val = str(val).strip()

    # ê¸°í˜¸ ë³€í™˜
    for k, v in char_to_num.items():
        val = val.replace(k, v)
    for k, v in symbol_map.items():
        val = val.replace(k, v)

    # 'ê°œ', " ì œê±°
    val = val.replace("ê°œ", "").replace('"', "")

    # ê´„í˜¸ ì²˜ë¦¬
    paren_match = re.findall(r"\((.*?)\)", val)
    val_outside = re.sub(r"\(.*?\)", "", val).strip()

    if paren_match:
        # ê´„í˜¸ ì•ˆ ê°’ë§Œ ìˆ«ì/ë¬¸ì ì¶”ì¶œ
        inner_vals = [p.strip() for p in paren_match]
        # ê´„í˜¸ ë°– ê°’ë„ ìˆ«ìë§Œ ê°™ë‹¤ë©´ ë¬´ì‹œ
        if all(v.isdigit() for v in inner_vals) and val_outside.isdigit() and int(val_outside) == int(inner_vals[0]):
            return int(inner_vals[0])
        # ë‹¨ì¼ ê´„í˜¸
        if len(inner_vals) == 1:
            return parse_value(inner_vals[0])
        return [parse_value(p) for p in inner_vals]
    elif val_outside:
        val = val_outside

    # ë”•ì…”ë„ˆë¦¬ íŒ¨í„´: {a:1, b:2}
    dict_match = re.match(r"^\{.*:.*\}$", val)
    if dict_match:
        try:
            dict_items = re.findall(r"(\S+?)\s*:\s*(\S+)", val)
            return {k: parse_value(v) for k, v in dict_items}
        except:
            pass

    # ë¦¬ìŠ¤íŠ¸ íŒ¨í„´: [a,b,c]
    list_match = re.findall(r"\[([^\[\]]+)\]", val)
    if list_match:
        items = list_match[0].split(",")
        return [parse_value(i.strip()) for i in items]

    # ì½¤ë§ˆ êµ¬ë¶„
    if "," in val:
        items = val.split(",")
        return [parse_value(i.strip()) for i in items]

    # ìˆ«ì ë³€í™˜
    if val.isdigit():
        return int(val)

    return val

def compare_answer(pred, gold):
    try:
        val1 = parse_value(pred)
        val2 = parse_value(gold)
        return val1 == val2
    except:
        return False
    
# ----------------------
# Annotation ì²˜ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼)
# ----------------------
def process_annotations(base_dir, annotation_dict, source_name, model, api_key):
    results = []
    jpg_files = [f for f in os.listdir(base_dir) if f.lower().endswith(".jpg")]

    for fname in tqdm(jpg_files, desc=f"Processing {source_name} ({model})"):
        fname_clean = clean_string(fname)
        matched = None
        for key, info in annotation_dict.items():
            file_clean = clean_string(info.get("file", ""))
            if file_clean == fname_clean:
                matched = info
                break
        if not matched:
            print(f"âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨: {fname}")
            continue

        image_path = os.path.join(base_dir, fname)
        response = safe_decode_image(model, api_key, image_path)
        if response is None:
            print(f"âš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨: {fname}")
            continue

        q_num, pred_answer = response_split(response)
        correct = compare_answer(pred_answer, matched["answer"])

        results.append({
            "source": source_name,
            "model": model,
            "book": matched["book"],
            "page": matched["page"],
            "problem_number": matched["problem_number"],
            "type": matched["type"],
            "answer": matched["answer"],
            "response": response,
            "pred_q_num": q_num,
            "pred_answer": pred_answer,
            "correct": correct
        })
    return results


# ----------------------
# ë©”ì¸ ì‹¤í–‰
# ----------------------
if __name__ == "__main__":
    ann1 = load_annotation_dict("test/images/LLM_annotation/annotation.txt")
    ann2 = load_annotation_dict("test/images/LLM_annotation_wrong/annotation_wrong_answer.txt")

    # ëª¨ë¸ê³¼ API í‚¤ ì„¤ì •
    models = {
        "meta-llama/llama-4-scout-17b-16e-instruct": os.environ.get("GROQ_API_KEY"),
        "gpt-4o": os.environ.get("OPENAI_API_KEY"),
        "gemini-2.0-flash-exp": os.environ.get("GEMINI_API_KEY")  # models/ ì œê±°
    }

    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ í•„í„°ë§
    available_models = {}
    for model_name, api_key in models.items():
        if api_key:
            available_models[model_name] = api_key
        else:
            print(f"âš ï¸ {model_name}ì˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

    data_sources = [
        ("test/images/LLM_annotation", ann1, "LLM_annotation"),
        ("test/images/LLM_annotation_wrong", ann2, "LLM_annotation_wrong")
    ]

    # ê° ëª¨ë¸ì— ëŒ€í•´ ì²˜ë¦¬
    for model_name, api_key in available_models.items():
        print(f"\nğŸš€ {model_name} ëª¨ë¸ ì²˜ë¦¬ ì‹œì‘...")
        model_results = []
        
        for folder, ann_dict, source_name in data_sources:
            print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {source_name}")
            try:
                model_results.extend(process_annotations(folder, ann_dict, source_name, model_name, api_key))
            except Exception as e:
                print(f"âš ï¸ {source_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ê²°ê³¼ ì €ì¥
        if model_results:
            safe_model_name = re.sub(r"[^a-zA-Z0-9_-]", "_", model_name)
            output_path = f"./test/llm_agent/results/results_{safe_model_name}.csv"
            
            # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            with open(output_path, "w", newline="", encoding="utf-8") as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=[
                    "source", "model", "book", "page", "problem_number", "type",
                    "answer", "response", "pred_q_num", "pred_answer", "correct"
                ])
                writer.writeheader()
                writer.writerows(model_results)

            # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
            total = len(model_results)
            correct = sum(1 for r in model_results if r["correct"])
            accuracy = (correct / total * 100) if total > 0 else 0
            
            print(f"âœ… {output_path} ì €ì¥ ì™„ë£Œ")
            print(f"ğŸ“Š {model_name} ê²°ê³¼: {correct}/{total} (ì •í™•ë„: {accuracy:.2f}%)")
        else:
            print(f"âš ï¸ {model_name}ì— ëŒ€í•œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("\nğŸ‰ ëª¨ë“  ëª¨ë¸ ì²˜ë¦¬ ì™„ë£Œ!")